sentiments <- as_tibble(c("anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust"))
print("Plato")
sentence.df=as_tibble(sentence.list)%>%
filter(school=="plato", word.count>=4)%>%
select(sentences, anger:trust)
sentence.df=as.data.frame(sentence.df)
s <-as.character(sentence.df$sentences[apply(sentence.df[,-1], 2, which.max)])
print(cbind(sentiments,
s))
sentiments <- as_tibble(c("anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust"))
print("Plato")
sentence.df=as_tibble(sentence.list)%>%
filter(school=="plato", word.count>=4)%>%
select(sentences, anger:trust)
sentence.df=as.data.frame(sentence.df)
max.sentiment <-as.character(sentence.df$sentences[apply(sentence.df[,-1], 2, which.max)])
print(cbind(sentiments,
max.sentiment))
sentence.list=NULL
for(i in 1:nrow(philosophy_data)){
sentences = sent_detect(philosophy_data$sentence_spacy[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences) > 0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
emotions=(1/(word.count+0.01)*as.matrix(emotions))
sentence.list=rbind(sentence.list,
cbind(philosophy_data[i,-ncol(philosophy_data)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
View(sentence.list)
sentence.list=NULL
for(i in 1:nrow(philosophy_data)){
sentences = sent_detect(philosophy_data$sentence_spacy[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences) > 0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
emotions=(1/(word.count+0.01)*as.matrix(emotions))
sentence.list=rbind(sentence.list,
cbind(philosophy_data[i,-ncol(philosophy_data)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
View(sentence.list)
sample <- sample(x=philosophy_data, size=36080, replace=FALSE)
View(philosophy_data)
sample <- sample(x=philosophy_data, size=36080, replace=FALSE)
philosophy_data %>% group_by(author, school, title)%>% count(title)
sample <- sample(x=philosophy_data, size=3608, replace=FALSE)
sample <- sample(x=philosophy_data, size=36, replace=FALSE)
sample <- sample_frac(philosophy_data, 0.1)
packages.used=c("rvest", "tibble",
"sentimentr", "gplots", "dplyr", "qdap",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library(ggplot2)
library(purrr)
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
print(R.version)
library(readr)
philosophy_data <- read_csv("../data/philosophy_data.csv")
str(philosophy_data)
philosophy_data$ntokens <- unlist(map(map(map(philosophy_data$tokenized_txt, strsplit, "', '"),unlist),length))
ggplot(data = philosophy_data,aes(x = title))+
geom_bar(width = 0.4,position = position_dodge(width=0.5))+
labs(title = "count for philosophy titles")+
theme(axis.text.x = element_text(angle = 90))
ggplot(data = philosophy_data,aes(x = author))+
geom_bar(width = 0.4,position = position_dodge(width=0.5))+
labs(title = "count for philosophy authors")+
theme(axis.text.x = element_text(angle = 90))
ggplot(data = philosophy_data,aes(x = school))+
geom_bar(width = 0.4,position = position_dodge(width=0.5))+
labs(title = "count for philosophy schools")+
theme(axis.text.x = element_text(angle = 90))
ggplot(data = philosophy_data,aes(x = sentence_length))+
geom_histogram(binwidth = 10)+
labs(title = "count for philosophy sentence length")
ggplot(data = philosophy_data, aes(x = ntokens))+
geom_histogram(binwidth = 2)+
labs(title = "count for philosophy number of tokens")
ggplot(data = philosophy_data, aes(x = school, y = sentence_length))+
geom_boxplot()+
theme(axis.text.x = element_text(angle = 90))+
labs(title = "boxplot for sentence length by school")
ggplot(data = philosophy_data, aes(x = school, y = ntokens))+
geom_boxplot()+
theme(axis.text.x = element_text(angle = 90))+
labs(title = "boxplot for number of tokens by school")
philosophy_data %>% group_by(author, school)%>% summarise(sentence_length_mean = mean(sentence_length), ntokens_mean = mean(ntokens))
philosophy_data %>% group_by(author, school)%>% count()
philosophy_data %>% group_by(author, school, title)%>% count(title)
sample <- sample_frac(philosophy_data, 0.1)
sentence.list=NULL
for(i in 1:nrow(sample)){
sentences = sent_detect(sample$sentence_spacy[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences) > 0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
emotions=(1/(word.count+0.01)*as.matrix(emotions))
sentence.list=rbind(sentence.list,
cbind(sample[i,-ncol(sample)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list=
sentence.list%>%
filter(!is.na(word.count))
sentiments <- as_tibble(c("anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust"))
print("Plato")
sentence.df=as_tibble(sentence.list)%>%
filter(school=="plato", word.count>=4)%>%
select(sentences, anger:trust)
sentence.df=as.data.frame(sentence.df)
max.sentiment <-as.character(sentence.df$sentences[apply(sentence.df[,-1], 2, which.max)])
print(cbind(sentiments,
max.sentiment))
schools <- unique(philosophy_data$school)
s <- "plato"
text <- sample %>% filter(school == s)
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
print(paste("This is plot for", s))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 2,
max.words=200,
random.order=FALSE,
rot.per=0.15,
scale = c(10,.3),
colors=brewer.pal(9,"Dark2"),
vfont=c("serif","plain"))
library(wordcloud)
s <- "plato"
text <- sample %>% filter(school == s)
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
print(paste("This is plot for", s))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 2,
max.words=200,
random.order=FALSE,
rot.per=0.15,
scale = c(10,.3),
colors=brewer.pal(9,"Dark2"),
vfont=c("serif","plain"))
for (i in schools) {
print(i)
sentence.df=as_tibble(sentence.list)%>%
filter(school==i, word.count>=4)%>%
select(sentences, anger:trust)
sentence.df=as.data.frame(sentence.df)
max.sentiment <-as.character(sentence.df$sentences[apply(sentence.df[,-1], 2, which.max)])
print(cbind(sentiments,
max.sentiment))
text <- sample %>% filter(school == i)
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234) # for reproducibility
print(paste("This is plot for", i))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 2,
max.words=200,
random.order=FALSE,
rot.per=0.15,
scale = c(10,.3),
colors=brewer.pal(9,"Dark2"),
vfont=c("serif","plain"))
}
packages.used=c("rvest", "tibble", "sentimentr", "gplots", "dplyr", "qdap",
"tm", "syuzhet", "factoextra", "beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext", "wordcloud", "ggplot2",
"purrr", "readr", "tidytext", "knitr", "shiny")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
library("wordcloud")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library("ggplot2")
library("purrr")
library("readr")
library("tidytext")
library("knitr")
library("shiny")
#show R version
print(R.version)
#import data and save it to dataframe named philosophy_data
library(readr)
philosophy_data <- read_csv("../data/philosophy_data.csv")
#overview of the data structure
str(philosophy_data)
#count the number of tokens for each sentence
philosophy_data$ntokens <- unlist(map(map(map(philosophy_data$tokenized_txt,
strsplit, "', '"),
unlist),
length))
#plot the count of sentences based on book titles
ggplot(data = philosophy_data,
aes(x = title))+
geom_bar(width = 0.4,
position = position_dodge(width = 0.5))+
labs(title = "count of sentences based on book titles")+
theme(axis.text.x = element_text(angle = 90))
#plot the count of sentences based on author name
ggplot(data = philosophy_data,
aes(x = author))+
geom_bar(width = 0.4,
position = position_dodge(width = 0.5))+
labs(title = "count of sentences based on author name")+
theme(axis.text.x = element_text(angle = 90))
#plot the count of sentences based on philosophy schools
ggplot(data = philosophy_data,
aes(x = school))+
geom_bar(width = 0.4,
position = position_dodge(width=0.5))+
labs(title = "count of sentences based on philosophy schools")+
theme(axis.text.x = element_text(angle = 90))
#plot the count of sentence length based on philosophy schools
ggplot(data = philosophy_data, aes(x = school, y = sentence_length))+
geom_boxplot()+
theme(axis.text.x = element_text(angle = 90))+
labs(title = "count of sentence length based on philosophy schools")
#plot the count of tokens based on philosophy schools
ggplot(data = philosophy_data, aes(x = school,
y = ntokens))+
geom_boxplot()+
theme(axis.text.x = element_text(angle = 90))+
labs(title = "count of tokens based on philosophy schools")
#group philosophy data by school and author and compute the mean of sentence length and number of tokens
mean_analysis <- philosophy_data %>%
group_by(author, school) %>%
summarise(sentence_length_mean = mean(sentence_length),
ntokens_mean = mean(ntokens)) %>% arrange(desc(sentence_length_mean))
#print the top six lines arranged by mean of sentence length descending order
head(mean_analysis)
#randomly sample 10% of the data since my computer is not able to process such big data
set.seed(10086)
sample <- sample_frac(philosophy_data, 0.1)
#reformatting the sentences and add 8 columns of sentiment to the data frame
sentence.list = NULL
for(i in 1:nrow(sample)){
sentences = sent_detect(sample$sentence_spacy[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences) > 0){
emotions = get_nrc_sentiment(sentences)
word.count = word_count(sentences)
emotions = (1 / (word.count + 0.01) * as.matrix(emotions))
sentence.list = rbind(sentence.list,
cbind(sample[i, -ncol(sample)],
sentences = as.character(sentences),
word.count,
emotions,
sent.id = 1:length(sentences)
)
)
}
}
#remove the sentence where word count is 0
sentence.list <-
sentence.list %>%
filter(!is.na(word.count))
#same the name of sentiments to a tibble named sentiments
sentiments <- as_tibble(c("anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust"))
#find unique school names and save it to a vector school
schools <- unique(philosophy_data$school)
#print the sentence having the greatest eight emotions by school
for (i in schools) {
print(i)
sentence.df = as_tibble(sentence.list) %>%
filter(school == i,
word.count >= 4) %>%
select(sentences,
anger:trust)
sentence.df = as.data.frame(sentence.df)
max.sentiment <- as.character(sentence.df$sentences[apply(sentence.df[,-1], 2, which.max)])
print(cbind(sentiments,
max.sentiment))
#print the corresponding wordcloud by school
text <- sample %>% filter(school == i)
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(10086)
print(paste("This is plot for", i))
wordcloud(words = df$word,
freq = df$freq,
min.freq = 2,
max.words = 200,
random.order = FALSE,
rot.per = 0.15,
scale = c(10,.3),
colors = brewer.pal(9,"Dark2"),
vfont = c("serif","plain"))
}
schools
plato <- sample %>% filter(school == "plato")
write.table(plato$sentence_spacy, file = "../data/schools/plato.txt", sep = "", row.names = FALSE)
aristotle <- sample %>% filter(school == "aristotle")
write.table(aristotle$sentence_spacy, file = "../data/schools/aristotle.txt", sep = "", row.names = FALSE)
empiricism <- sample %>% filter(school == "empiricism")
write.table(empiricism$sentence_spacy, file = "../data/schools/empiricism.txt", sep = "", row.names = FALSE)
rationalism <- sample %>% filter(school == "rationalism")
write.table(rationalism$sentence_spacy, file = "../data/schools/rationalism.txt", sep = "", row.names = FALSE)
analytic <- sample %>% filter(school == "analytic")
write.table(analytic$sentence_spacy, file = "../data/schools/analytic.txt", sep = "", row.names = FALSE)
continental <- sample %>% filter(school == "continental")
write.table(continental$sentence_spacy, file = "../data/schools/continental.txt", sep = "", row.names = FALSE)
phenomenology <- sample %>% filter(school == "phenomenology")
write.table(phenomenology$sentence_spacy, file = "../data/schools/phenomenology.txt", sep = "", row.names = FALSE)
german_idealism <- sample %>% filter(school == "german_idealism")
write.table(german_idealism$sentence_spacy, file = "../data/schools/german_idealism.txt", sep = "", row.names = FALSE)
communism <- sample %>% filter(school == "communism")
write.table(communism$sentence_spacy, file = "../data/schools/communism.txt", sep = "", row.names = FALSE)
capitalism <- sample %>% filter(school == "capitalism")
write.table(capitalism$sentence_spacy, file = "../data/schools/capitalism.txt", sep = "", row.names = FALSE)
stoicism <- sample %>% filter(school == "stoicism")
write.table(stoicism$sentence_spacy, file = "../data/schools/stoicism.txt", sep = "", row.names = FALSE)
nietzsche <- sample %>% filter(school == "nietzsche")
write.table(nietzsche$sentence_spacy, file = "../data/schools/nietzsche.txt", sep = "", row.names = FALSE)
feminism <- sample %>% filter(school == "feminism")
write.table(feminism$sentence_spacy, file = "../data/schools/feminism.txt", sep = "", row.names = FALSE)
folder.path="../data/schools/"
schools=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(schools, 6, nchar(schools)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
ff.all
tdm.all<-TermDocumentMatrix(ff.all)
tdm.all
# Turn the Term Document Matrix into a tidy tibble
tdm.tidy=tidy(tdm.all)
kable(tdm.tidy[1:10,])
# Get the Overall Counts over the Whole Corpus
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
kable(tdm.overall[101:110,])
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x) weightTfIdf(x,normalize=FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
ff.dtm <- ff.dtm %>% na.omit()
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('school1', 'School1',
schools,
selected=schools[5])),
column(4, selectInput('school2', 'School2', schools,
selected=schools[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$school1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$school1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$school2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$school2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
random.color=FALSE,
colors=brewer.pal(9,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
random.color=FALSE,
colors=brewer.pal(9,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
save.image("E:/Github/spring-2022-prj1-dajianjue1999/output/out.RData")
save.image("E:/Github/spring-2022-prj1-dajianjue1999/data/out.RData")
